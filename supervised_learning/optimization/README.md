# OPTIMIZATION


![OPS](https://s3.eu-west-3.amazonaws.com/hbtn.intranet/uploads/medias/2018/11/2bc924532bc4a901e74d.jpg?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA4MYA5JM5DUTZGMZG%2F20230623%2Feu-west-3%2Fs3%2Faws4_request&X-Amz-Date=20230623T190812Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=fa2b432fa68132e82a934fd694fac75424f1fb6503270cb2649a2e72fe4c978c)

## General

- What is a hyperparameter?
- How and why do you normalize your input data?
- What is a saddle point?
- What is stochastic gradient descent?
- What is mini-batch gradient descent?
- What is a moving average? How do you implement it?
- What is gradient descent with momentum? How do you implement it?
- What is RMSProp? How do you implement it?
- What is Adam optimization? How do you implement it?
- What is learning rate decay? How do you implement it?
- What is batch normalization? How do you implement it?

